{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Neural Collaborative Filtering\n","\n","Las redes neuronales son un subconjunto de algoritmos dentro de la familia del *machine learning* que ofrecen unos excelentes resultados a la mayoría de los problemas de aprendizaje supervisado. A diferencia de los modelos de *machine learning* clásicos, las redes neuronales suelen requerir poca preparación de los datos por parte de los científicos de datos, ya que los propios modelos se encargan de aprender dichos pre-procesamientos. Las redes neuronales han revolucionado el *machine learning* siendo capaces de mejorar la capacidad predictiva de la mayoría de los modelos tradicionales.\n","\n","El campo de los sistemas de recomendación en general y del filtrado colaborativo en particular no ha sido ajeno a esta revolución y se han desarrollado algoritmos de filtrado colaborativo utilizando redes neuronales. A esta familia de algoritmos se la conoce como *Neural Collaborative Filtering*."],"metadata":{"id":"Myy-e1-MdxDf"}},{"cell_type":"markdown","source":["## Generalized Matrix Factorization (GMF)\n","\n","El primer hito por alcanzar de los modelos de redes neuronales para filtrado colaborativo era lograr manejar la dispersión de la matriz de votaciones durante el entrenamiento de la red. La idea más básica que se nos podría ocurrir cuando construimos una red neuronal para resolver el problema de filtrado colaborativo es la de pasarle el vector de votaciones del usuario. Sin embargo, esta idea es inviable al ser este vector disperso. ¿Qué entrada le damos a la red cuando el usuario no ha votado el ítem? Todas las posibles respuestas reportan complicaciones:\n","\n","- Poner un 0 en los votos faltantes indica a la red que al usuario no le ha gustado el ítem.\n","- Poner un valor alto en los votos faltantes indica a la red que al usuario le encanta el ítem.\n","- Poner la votación media general, la votación media del usuario o la votación media del ítem, no permitirá a la red aprender las características propias del usuario al tener una dispersión muy alta de los votos (>90%).\n","\n","Por tanto, la resolución de este problema implica definir una estrategia de entrada para la red que sí permita manejar la dispersión de los datos. En concreto, necesitamos alimentar a la red con duplas `<usuario, item>` en las que la salida sea una `votación`. Generalmente, los usuarios y los ítems son representados por un código numérico (ej. el usuario `4` o el ítem `42`), pero ¿qué sucede si la entrada de la red son estos códigos numéricos? Que la red tendrá que corregir durante su aprendizaje el sesgo introducido por el valor numérico de los usuarios y los ítems: la red deberá aprender que el usuario `1000` no es 1000 veces más grande que el usuario `1`, si no que tienen esos números por puro azar.\n","\n","Es por esto por lo que, en lugar de utilizar los códigos de los usuarios e ítems como entrada se recurre a utilizar una capa de *embedding*. La capa de *embedding* es un tipo de capa densa especial en la que se garantiza que todas sus entradas son `0` menos `1`, es decir, se representa una entrada discreta mediante *one-hot-encoding*. En el caso del filtrado colaborativo, se definen dos capas de *embedding* como entrada, una para los usuarios y otra para los ítems, que tienen por dimesión máxima el número de usuarios y el número de ítems respectivamente. Cuando se quiere predecir la votación del usuario `4` para el ítem `42`, las neuronas del *embedding* correspondientes a dicho usuario e ítem se pondrán a `1` y el resto quedarán a `0`.\n","\n","A partir de este punto, se plantean diferentes arquitecturas de red que permiten estimar el voto que un usuario le otorgará a un ítem. La más sencilla de todas ellas se denomina *Generalized Matrix Factorization (GMF)* y tiene el siguiente aspecto:\n","\n","![GMF](https://i.ibb.co/3hNBVK3/gmf.png)\n","\n","Tras las capas de *embedding* se coloca una capa *dot* que combina las dos entradas mediante el producto escalar. La salida de esta capa es el voto. Hay que destacar que esta arquitectura es equivalente al modelo PMF, puesto el tamaño de la capa *dot* define el número de factores latentes a combinar linealmente y los pesos de la red equivalen a $p_u$ y $q_i$ de dicho modelo.\n","\n","Veamos como implementar este modelo con `keras`."],"metadata":{"id":"arZx4WWMe-hy"}},{"cell_type":"markdown","source":["Importamos las librerías necesarias:"],"metadata":{"id":"soEoj7q9mPlo"}},{"cell_type":"code","source":["import urllib.request\n","\n","import math\n","import numpy as np\n","\n","from keras.models import Model\n","from keras.layers import Embedding, Flatten, Input, Dense, Concatenate, Dot"],"metadata":{"id":"XipB_vjqFSfI"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Definimos el número de usuarios e ítems:"],"metadata":{"id":"gFl7gt95mSSR"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"pxoczYlxE7sR"},"outputs":[],"source":["NUM_USERS = 943\n","NUM_ITEMS = 1682"]},{"cell_type":"markdown","source":["Cargamos los votos de entrenamiento. La carga de estos datos, por imposición de `keras` no se hace en una matriz como en los modelos de factorización matricial. Se generan dos *arrays* con los códigos de los usuarios y los ítems y un tercer *array* con las votaciones:"],"metadata":{"id":"Oj7OQsGYmVMh"}},{"cell_type":"code","source":["X_train = [np.array([], dtype=int), np.array([], dtype=int)]\n","y_train = np.array([], dtype=int)\n","\n","training_file = urllib.request.urlopen(\"https://drive.upm.es/s/tDdluElfGInyUnU/download\")\n","for line in training_file:\n","  [u, i, rating] = line.decode(\"utf-8\").split(\"::\")\n","  X_train[0] = np.append(X_train[0], int(u))\n","  X_train[1] = np.append(X_train[1], int(i))\n","  y_train = np.append(y_train, int(rating))"],"metadata":{"id":"OkydN86fFPeZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_train"],"metadata":{"id":"gRb4HsglGW0I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_train"],"metadata":{"id":"WqTzNwiwGgZr"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Cargamos también los votos de test del mismo modo:"],"metadata":{"id":"x20AHTttmmJ4"}},{"cell_type":"code","source":["X_test = [np.array([], dtype=int), np.array([], dtype=int)]\n","y_test = np.array([], dtype=int)\n","\n","test_file = urllib.request.urlopen(\"https://drive.upm.es/s/Jn75Vg6okOPsgZu/download\")\n","for line in test_file:\n","  [u, i, rating] = line.decode(\"utf-8\").split(\"::\")\n","  X_test[0] = np.append(X_test[0], int(u))\n","  X_test[1] = np.append(X_test[1], int(i))\n","  y_test = np.append(y_test, int(rating))"],"metadata":{"id":"L06N8E7uFQ1y"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X_test"],"metadata":{"id":"Rk6CPCQ-IY0I"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y_test"],"metadata":{"id":"hyDnkikqIafE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Los hiper-parámetros de nuestro modelo serán el número de factores latentes (`latent_dim`) y el número de iteraciones del entrenamiento (`epochs`)."],"metadata":{"id":"5Rts84dhmrGF"}},{"cell_type":"code","source":["latent_dim = 5\n","epochs = 10"],"metadata":{"id":"seUnp23gFgPS"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Definimos nuestra arquitectura:"],"metadata":{"id":"mbtOKh12m4Gk"}},{"cell_type":"code","source":["user_input = Input(shape=[1])\n","user_embedding = # defina la capa de embedding del usuario\n","user_vec = Flatten()(user_embedding)\n","\n","item_input = Input(shape=[1])\n","item_embedding = # defina la capa de embedding del item\n","item_vec = Flatten()(item_embedding)\n","\n","output = # defina la dot que combine user_vec e item_vec\n","\n","GMF = Model([user_input, item_input], output)"],"metadata":{"id":"rVQb1q4HFei2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compilamos y entrenamos el modelo:"],"metadata":{"id":"EUAhQoilm_xq"}},{"cell_type":"code","source":["GMF.compile(optimizer='adam', metrics=['mae'], loss='mean_squared_error')\n","GMF.summary()\n","GMF.fit(X_train, y_train, epochs=epochs, verbose=1)"],"metadata":{"id":"hJ-dfpKgF03Z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Estimamos las predicciones de test:"],"metadata":{"id":"4HHqkHmZnHp6"}},{"cell_type":"code","source":["y_pred = GMF.predict(X_test)\n","y_pred"],"metadata":{"id":"cBhCYv7JJLIE"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Medimos el error:"],"metadata":{"id":"zSLJCSQKnJ9p"}},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error\n","mean_absolute_error(y_test, y_pred)"],"metadata":{"id":"lgI7iIUCJYpJ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Multi Layer Perceptron (MLP)\n","\n","El modelo GMF tiene un problema: no aporta nada nuevo. Los usuarios e ítems son mapeados en un espacio latente y el voto es calculado como una combinación lineal de los factores latentes de cada usuario e ítem. Este modelo utiliza redes neuronales, pero no explota su principal arma: romper la linealidad de las operaciones.\n","\n","Para ello, el modelo MLP mejora al modelo GMF permitiendo una combinación no-lineal de los factores latentes. Su arquitectura es la siguiente:\n","\n","![MLP](https://i.ibb.co/pRpD4Hv/mlp.png)\n","\n","Al igual que en GMF, los usuarios e ítems son representados mediante dos capas de *embedding*, sin embargo, estas no son combinadas mediante una capa *dot* si no que se unen en una capa *concatenate* a la que le suceden diferentes capas densas. A esa sucesión de capas densas se les conoce como MLP y su topología se configurar en función del conjunto de datos. Finalmente, se da como salida la predicción del voto.\n","\n","Veamos su implementación en `keras`."],"metadata":{"id":"uuZCAhRKJ9Jq"}},{"cell_type":"markdown","source":["Definimos los mismos hiper-parámetros que en el modelo anterior:"],"metadata":{"id":"niGzocRYqRee"}},{"cell_type":"code","source":["latent_dim = 5\n","epochs = 10"],"metadata":{"id":"-SInwu4icxcL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Definimos la arquitectura, en este caso con dos capas densas para el MLP de 20 y 10 neuronas:"],"metadata":{"id":"F7nMI6pFqVXD"}},{"cell_type":"code","source":["user_input = Input(shape=[1])\n","user_embedding = # defina la capa embedding del usuario\n","user_vec = Flatten()(user_embedding)\n","\n","item_input = Input(shape=[1])\n","item_embedding = # defina la capa embedding del item\n","item_vec = Flatten()(item_embedding)\n","\n","concat = # defina la capa concatenate para combinar user_vec e item_vec\n","\n","output = # defina las capas necesarias para su MLP\n","\n","MLP = Model([user_input, item_input], output)"],"metadata":{"id":"dh20X7NSJ_eN"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Compilamos y entrenamos el modelo:"],"metadata":{"id":"YFNn6dtrqZoT"}},{"cell_type":"code","source":["MLP.compile(optimizer='adam', metrics=['mae'], loss='mean_squared_error')\n","MLP.summary()\n","MLP.fit(X_train, y_train, epochs=epochs, verbose=1)"],"metadata":{"id":"LdY5aBYXczeX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Calculamos las predicciones:"],"metadata":{"id":"rPm3riOiqb6D"}},{"cell_type":"code","source":["y_pred = MLP.predict(X_test)\n","y_pred"],"metadata":{"id":"kMuoS5YOc9Sw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Medimos el error:"],"metadata":{"id":"XCy3bh6Dqdg6"}},{"cell_type":"code","source":["from sklearn.metrics import mean_absolute_error\n","mean_absolute_error(y_test, y_pred)"],"metadata":{"id":"JAUAgpo5c_S1"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Referencias\n","\n","He, X., Liao, L., Zhang, H., Nie, L., Hu, X., & Chua, T. S. (2017, April). **Neural collaborative filtering**. In Proceedings of the 26th international conference on world wide web (pp. 173-182).\n"],"metadata":{"id":"5Fma-ovEqmWz"}}]}