{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af0d13e1",
   "metadata": {},
   "source": [
    "Creamos la matriz de ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b109c630",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "from funciones import (preprocesar_dataframe_animes, \n",
    "                       rating_average, correlation_similarity, jmsd_similarity, # Funciones de similitud y avg\n",
    "                       get_neighbors, # Búsqueda de vecinos\n",
    "                       average_prediction, weighted_average_prediction, deviation_from_mean_prediction, # Agregación\n",
    "                       get_recommendations, # Para métricas de ranking\n",
    "                       get_mae, get_rmse, get_precision, get_recall, get_f1, get_ndcg, # Métricas globales\n",
    "                       # No necesitas importar las get_user_* de métricas aquí si solo usas las globales\n",
    "                       # a menos que quieras hacer análisis por usuario.\n",
    "                       # También importa has_test_ratings, get_ordered_test_animes, get_user_idcg, get_user_dcg si son usadas por las métricas globales\n",
    "                       # que importas, lo cual parece ser el caso para nDCG.\n",
    "                       get_ordered_test_animes, get_user_idcg, get_user_dcg, # Necesarias para get_ndcg\n",
    "                       get_metricas # Tu función para imprimir todas las métricas\n",
    "                      )\n",
    "RANDOM_STATE = 42 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f24c6750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NUM_USERS: 1000, NUM_ANIMES: 3914\n",
      "  Tamaño train_df: 83964, Tamaño test_df: 20968\n"
     ]
    }
   ],
   "source": [
    "PATH_RATINGS_CSV = 'csv/rating.csv'    # Ajusta esta ruta\n",
    "MIN_USER_RATINGS = 5                   # Tu umbral\n",
    "MIN_ANIME_RATINGS = 5                  # Tu umbral\n",
    "SAMPLE_NUM_USERS_FOR_DEV = 1000\n",
    "\n",
    "(train_df, test_df, \n",
    " ratings_train_matrix, ratings_test_matrix,\n",
    " NUM_USERS, NUM_ANIMES, MIN_RATING, MAX_RATING, SCORES\n",
    ") = preprocesar_dataframe_animes( # Tu función importada\n",
    "    dataframe_path=PATH_RATINGS_CSV, # El nombre del parámetro en tu función\n",
    "    n_user_ratings=MIN_USER_RATINGS, # El nombre del parámetro en tu función\n",
    "    n_anime_ratings=MIN_ANIME_RATINGS, # El nombre del parámetro en tu función\n",
    "    num_users=SAMPLE_NUM_USERS_FOR_DEV,    # El nombre del parámetro en tu función\n",
    "    test_size=0.2,\n",
    "    RANDOM_STATE=RANDOM_STATE\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"  NUM_USERS: {NUM_USERS}, NUM_ANIMES: {NUM_ANIMES}\")\n",
    "print(f\"  Tamaño train_df: {len(train_df)}, Tamaño test_df: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30ed8ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo base (media del usuario):\n",
      "MAE =  1.0278554327359957\n",
      "RMSE =  1.2332543271239766\n",
      "Precision =  0.916025641025641\n",
      "Recall =  0.021991373376716507\n",
      "F1 =  0.13880496180538138\n"
     ]
    }
   ],
   "source": [
    "# Cálculo del modelo base: predicción por media del usuario\n",
    "from funciones import rating_average, get_metricas\n",
    "\n",
    "# inicializamos la matriz de predicciones\n",
    "predictions_media = [[None for _ in range(NUM_ANIMES)] for _ in range(NUM_USERS)]\n",
    "\n",
    "# rellenamos la predicción con la media del usuario u\n",
    "for u in range(NUM_USERS):\n",
    "    avg_u = rating_average(ratings_train_matrix, NUM_ANIMES, u)\n",
    "    for i in range(NUM_ANIMES):\n",
    "        predictions_media[u][i] = avg_u\n",
    "\n",
    "# evaluamos el modelo base\n",
    "print(\"Modelo base (media del usuario):\")\n",
    "get_metricas(ratings_test_matrix, NUM_ANIMES, NUM_USERS, predictions_media, theta=7, N=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e47eba",
   "metadata": {},
   "source": [
    "Vamos a implementar ahora la JMSD similitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0a1728e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo KNN (k=10, jmsd + average):\n",
      "MAE =  1.2259263980624535\n",
      "RMSE =  1.479130055834072\n",
      "Precision =  0.9069769503546085\n",
      "Recall =  0.7666369509971367\n",
      "F1 =  0.7876908848425289\n"
     ]
    }
   ],
   "source": [
    "from funciones import jmsd_similarity, get_neighbors, average_prediction, has_test_ratings\n",
    "\n",
    "k = 10 \n",
    "\n",
    "predictions_knn = [[None for _ in range(NUM_ANIMES)] for _ in range(NUM_USERS)]\n",
    "\n",
    "for u in range(NUM_USERS):\n",
    "    if has_test_ratings(ratings_test_matrix, NUM_ANIMES, u):\n",
    "        \n",
    "        similarities = [None if u == v else jmsd_similarity(\n",
    "            ratings_train_matrix, NUM_ANIMES, MIN_RATING, MAX_RATING, u, v\n",
    "        ) for v in range(NUM_USERS)]\n",
    "        \n",
    "        neighbors = get_neighbors(k, similarities)\n",
    "        \n",
    "        for i in range(NUM_ANIMES):\n",
    "            if ratings_test_matrix[u][i] is not None:\n",
    "                predictions_knn[u][i] = average_prediction(ratings_train_matrix, i, neighbors)\n",
    "\n",
    "print(\"Modelo KNN (k=10, jmsd + average):\")\n",
    "get_metricas(ratings_test_matrix, NUM_ANIMES, NUM_USERS, predictions_knn, theta=7, N=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6728a65",
   "metadata": {},
   "source": [
    "El KNN ha mejorado bastante el Recall y el F1 respecto al modelo base, que es lo que nos interesa para la recomendación real, pero ha empeorado el MAE y RMSE. Esto era esperable porque no predice tan bien valores exactos, sino que está buscando acertar los items más relevantes.\n",
    "\n",
    "Igualmente la precisión es bastante alta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2d1f4806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " k evaluado = 5\n",
      "\n",
      " métricas para KNN (k = 5, jmsd + average):\n",
      "MAE =  1.220294728444326\n",
      "RMSE =  1.47181896265817\n",
      "Precision =  0.9101308235126809\n",
      "Recall =  0.7956852987257566\n",
      "F1 =  0.8106379525212875\n",
      "\n",
      " k evaluado = 20\n",
      "\n",
      " métricas para KNN (k = 20, jmsd + average):\n",
      "MAE =  1.2189339836591828\n",
      "RMSE =  1.4692976503572879\n",
      "Precision =  0.9053714908828528\n",
      "Recall =  0.7474217181394548\n",
      "F1 =  0.7682610649469984\n",
      "\n",
      " k evaluado = 40\n",
      "\n",
      " métricas para KNN (k = 40, jmsd + average):\n",
      "MAE =  1.17178385273052\n",
      "RMSE =  1.4111055663517262\n",
      "Precision =  0.9053096525966686\n",
      "Recall =  0.7355213354375992\n",
      "F1 =  0.7601104267780977\n"
     ]
    }
   ],
   "source": [
    "ks = [5, 20, 40]\n",
    "\n",
    "for k in ks:\n",
    "    print(f\"\\n k evaluado = {k}\")\n",
    "    predictions_knn = [[None for _ in range(NUM_ANIMES)] for _ in range(NUM_USERS)]\n",
    "\n",
    "    for u in range(NUM_USERS):\n",
    "        if has_test_ratings(ratings_test_matrix, NUM_ANIMES, u):\n",
    "\n",
    "            similarities = [\n",
    "                None if u == v else jmsd_similarity(\n",
    "                    ratings_train_matrix, NUM_ANIMES, MIN_RATING, MAX_RATING, u, v\n",
    "                ) for v in range(NUM_USERS)\n",
    "            ]\n",
    "\n",
    "            neighbors = get_neighbors(k, similarities)\n",
    "\n",
    "            for i in range(NUM_ANIMES):\n",
    "                if ratings_test_matrix[u][i] is not None:\n",
    "                    predictions_knn[u][i] = average_prediction(ratings_train_matrix, i, neighbors)\n",
    "\n",
    "    print(f\"\\n métricas para KNN (k = {k}, jmsd + average):\")\n",
    "    get_metricas(ratings_test_matrix, NUM_ANIMES, NUM_USERS, predictions_knn, theta=7, N=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df74b4d4",
   "metadata": {},
   "source": [
    "vamos a probar otras formas de prediccion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98e052b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "k = 5 y método: average_prediction\n",
      "MAE =  1.220294728444326\n",
      "RMSE =  1.47181896265817\n",
      "Precision =  0.9101308235126809\n",
      "Recall =  0.7956852987257566\n",
      "F1 =  0.8106379525212875\n",
      "\n",
      "k = 5 y método: weighted_average_prediction\n",
      "MAE =  1.2220757342386632\n",
      "RMSE =  1.4729041334256756\n",
      "Precision =  0.9101308235126809\n",
      "Recall =  0.796131376106811\n",
      "F1 =  0.8109605824400361\n",
      "\n",
      "k = 5 y método: deviation_from_mean_prediction\n",
      "MAE =  1.0983929015237512\n",
      "RMSE =  1.310906489393617\n",
      "Precision =  0.911922536838549\n",
      "Recall =  0.7964706879557367\n",
      "F1 =  0.8117079788021256\n",
      "\n",
      "k = 10 y método: average_prediction\n",
      "MAE =  1.2259263980624535\n",
      "RMSE =  1.479130055834072\n",
      "Precision =  0.9069769503546085\n",
      "Recall =  0.7666369509971367\n",
      "F1 =  0.7876908848425289\n",
      "\n",
      "k = 10 y método: weighted_average_prediction\n",
      "MAE =  1.2275187871039943\n",
      "RMSE =  1.4788640518981893\n",
      "Precision =  0.9072960992907789\n",
      "Recall =  0.7670610639054529\n",
      "F1 =  0.7880267769162118\n",
      "\n",
      "k = 10 y método: deviation_from_mean_prediction\n",
      "MAE =  1.095439158821956\n",
      "RMSE =  1.3098715393968687\n",
      "Precision =  0.9074024822695016\n",
      "Recall =  0.7667710702393583\n",
      "F1 =  0.7879078783593239\n"
     ]
    }
   ],
   "source": [
    "from funciones import jmsd_similarity, get_neighbors, average_prediction, weighted_average_prediction, deviation_from_mean_prediction, has_test_ratings, get_metricas\n",
    "\n",
    "def evaluar_predicciones(k, metodo_pred):\n",
    "    print(f\"\\nk = {k} y método: {metodo_pred.__name__}\")\n",
    "    predictions_knn = [[None for _ in range(NUM_ANIMES)] for _ in range(NUM_USERS)]\n",
    "\n",
    "    for u in range(NUM_USERS):\n",
    "        if has_test_ratings(ratings_test_matrix, NUM_ANIMES, u):\n",
    "\n",
    "            similarities = [\n",
    "                None if u == v else jmsd_similarity(\n",
    "                    ratings_train_matrix, NUM_ANIMES, MIN_RATING, MAX_RATING, u, v\n",
    "                ) for v in range(NUM_USERS)\n",
    "            ]\n",
    "\n",
    "            neighbors = get_neighbors(k, similarities)\n",
    "\n",
    "            for i in range(NUM_ANIMES):\n",
    "                if ratings_test_matrix[u][i] is not None:\n",
    "                    if metodo_pred == deviation_from_mean_prediction:\n",
    "                        predictions_knn[u][i] = metodo_pred(ratings_train_matrix, NUM_ANIMES, u, i, neighbors)\n",
    "                    elif metodo_pred == weighted_average_prediction:\n",
    "                        predictions_knn[u][i] = metodo_pred(ratings_train_matrix, i, neighbors, similarities)\n",
    "                    else:\n",
    "                        predictions_knn[u][i] = metodo_pred(ratings_train_matrix, i, neighbors)\n",
    "\n",
    "    get_metricas(ratings_test_matrix, NUM_ANIMES, NUM_USERS, predictions_knn, theta=7, N=10)\n",
    "\n",
    "\n",
    "# Ejecutamos para k = 5 y 10, con los tres métodos\n",
    "for k in [5, 10]:\n",
    "    for metodo in [average_prediction, weighted_average_prediction, deviation_from_mean_prediction]:\n",
    "        evaluar_predicciones(k, metodo)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b962cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
